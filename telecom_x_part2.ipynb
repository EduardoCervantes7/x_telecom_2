{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb63ebf1",
   "metadata": {},
   "source": [
    "# Telecom X – Parte 2: Predicción de Cancelación (Churn)  \n",
    "Incluye: carga desde API JSON, limpieza, análisis exploratorio (correlación), preprocesado, entrenamiento de **Regresión Logística** y **Random Forest**, evaluación (accuracy, precision, recall, F1, AUC, matriz de confusión), interpretación (importancia y coeficientes) y conclusiones.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27072f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inicio de celda: explicación de la lógica de esta sección ---\n",
    "# (Opcional) Instalar imbalanced-learn para SMOTE si quieres usarlo.\n",
    "# Ejecuta esta celda solo si necesitas SMOTE.\n",
    "# !pip -q install imbalanced-learn\n",
    "print(\"Si necesitas SMOTE para balancear clases, descomenta la línea de pip install.\")\n",
    "# --- Fin de celda ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c49414f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inicio de celda: explicación de la lógica de esta sección ---\n",
    "# Importación de librerías necesarias\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Importación de librerías necesarias\n",
    "import pandas as pd\n",
    "# Importación de librerías necesarias\n",
    "import numpy as np\n",
    "# Importación de librerías necesarias\n",
    "import matplotlib.pyplot as plt\n",
    "# Importación de librerías necesarias\n",
    "import seaborn as sns\n",
    "\n",
    "# Importación de librerías necesarias\n",
    "from sklearn.model_selection import train_test_split\n",
    "# Importación de librerías necesarias\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "# Importación de librerías necesarias\n",
    "from sklearn.compose import ColumnTransformer, make_column_selector as selector\n",
    "# Importación de librerías necesarias\n",
    "from sklearn.pipeline import Pipeline\n",
    "# Importación de librerías necesarias\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "# Importación de librerías necesarias\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# Importación de librerías necesarias\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, f1_score,\n",
    "                             confusion_matrix, classification_report, roc_auc_score, roc_curve)\n",
    "\n",
    "# Asignación de variable o resultado intermedio\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Definición de una función\n",
    "def make_ohe():\n",
    "    \"\"\"Create OneHotEncoder with dense output in a way compatible with multiple sklearn versions.\"\"\"\n",
    "    try:\n",
    "# Asignación de variable o resultado intermedio\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False)\n",
    "    except TypeError:\n",
    "# Asignación de variable o resultado intermedio\n",
    "        return OneHotEncoder(handle_unknown=\"ignore\", sparse=False)\n",
    "\n",
    "# --- Fin de celda ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b3f08be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inicio de celda: explicación de la lógica de esta sección ---\n",
    "# 1) Cargar datos desde API JSON y aplanar campos tipo dict\n",
    "# Asignación de variable o resultado intermedio\n",
    "url = \"https://raw.githubusercontent.com/ingridcristh/challenge2-data-science-LATAM/main/TelecomX_Data.json\"\n",
    "# Asignación de variable o resultado intermedio\n",
    "df = pd.read_json(url)\n",
    "\n",
    "# Definición de una función\n",
    "def flatten_dataframe(df_):\n",
    "# Asignación de variable o resultado intermedio\n",
    "    df_flat = df_.copy()\n",
    "# Asignación de variable o resultado intermedio\n",
    "    cols_to_expand = [c for c in df_flat.columns if df_flat[c].apply(lambda x: isinstance(x, dict)).any()]\n",
    "# Bucle para iterar sobre datos\n",
    "    for c in cols_to_expand:\n",
    "# Asignación de variable o resultado intermedio\n",
    "        expanded = pd.json_normalize(df_flat[c])\n",
    "# Asignación de variable o resultado intermedio\n",
    "        expanded.columns = [f\"{c}_{subc}\" for subc in expanded.columns]\n",
    "# Asignación de variable o resultado intermedio\n",
    "        df_flat = df_flat.drop(columns=[c]).join(expanded)\n",
    "    return df_flat\n",
    "\n",
    "# Asignación de variable o resultado intermedio\n",
    "df = flatten_dataframe(df)\n",
    "print('Shape raw:', df.shape)\n",
    "df.head(3)\n",
    "# --- Fin de celda ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bb368ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inicio de celda: explicación de la lógica de esta sección ---\n",
    "# 2) Limpieza inicial: eliminar duplicados, mapear binarios y tipos\n",
    "# Eliminar duplicados considerando representación en string (maneja dicts)\n",
    "# Asignación de variable o resultado intermedio\n",
    "df = df.loc[~df.astype(str).duplicated()].reset_index(drop=True)\n",
    "\n",
    "# Mapeo robusto de valores binarios que podrían aparecer\n",
    "# Asignación de variable o resultado intermedio\n",
    "map_yes = {\"yes\", \"sí\", \"si\", \"true\", \"1\", \"y\"}\n",
    "# Asignación de variable o resultado intermedio\n",
    "map_no  = {\"no\", \"false\", \"0\", \"n\"}\n",
    "\n",
    "# Definición de una función\n",
    "def binarize(v):\n",
    "# Condición para ejecutar código según un criterio\n",
    "    if isinstance(v, str):\n",
    "# Asignación de variable o resultado intermedio\n",
    "        t = v.strip().lower()\n",
    "# Condición para ejecutar código según un criterio\n",
    "        if t in map_yes: return 1\n",
    "# Condición para ejecutar código según un criterio\n",
    "        if t in map_no:  return 0\n",
    "    return v\n",
    "\n",
    "# Asignación de variable o resultado intermedio\n",
    "df = df.applymap(binarize)\n",
    "\n",
    "# Intentar convertir object a numérico donde aplique, conservar strings si no se puede\n",
    "# Bucle para iterar sobre datos\n",
    "for col in df.columns:\n",
    "# Condición para ejecutar código según un criterio\n",
    "    if df[col].dtype == 'object':\n",
    "# Asignación de variable o resultado intermedio\n",
    "        df[col] = pd.to_numeric(df[col], errors='ignore')\n",
    "\n",
    "# Imputación diferenciada: numéricos -> 0 ; categóricas -> 'missing'\n",
    "# Asignación de variable o resultado intermedio\n",
    "num_cols_tmp = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "# Asignación de variable o resultado intermedio\n",
    "cat_cols_tmp = [c for c in df.columns if c not in num_cols_tmp]\n",
    "\n",
    "# Condición para ejecutar código según un criterio\n",
    "if num_cols_tmp:\n",
    "# Asignación de variable o resultado intermedio\n",
    "    df[num_cols_tmp] = df[num_cols_tmp].fillna(0)\n",
    "# Condición para ejecutar código según un criterio\n",
    "if cat_cols_tmp:\n",
    "# Asignación de variable o resultado intermedio\n",
    "    df[cat_cols_tmp] = df[cat_cols_tmp].fillna('missing').astype(str)\n",
    "\n",
    "# Feature opcional\n",
    "# Condición para ejecutar código según un criterio\n",
    "if 'MonthlyCharges' in df.columns:\n",
    "# Asignación de variable o resultado intermedio\n",
    "    df['Cuentas_Diarias'] = df['MonthlyCharges'] / 30\n",
    "\n",
    "print('Shape after cleaning:', df.shape)\n",
    "df.head(3)\n",
    "# --- Fin de celda ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c0df5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inicio de celda: explicación de la lógica de esta sección ---\n",
    "# 3) EDA rápido: revisar objetivo y correlaciones numéricas\n",
    "# Asignación de variable o resultado intermedio\n",
    "target_col = 'Churn'\n",
    "# Condición para ejecutar código según un criterio\n",
    "if target_col not in df.columns:\n",
    "    raise ValueError(f\"No encontré la columna objetivo '{target_col}' en el dataframe.\")\n",
    "\n",
    "# Asegurar que target sea 0/1\n",
    "# Asignación de variable o resultado intermedio\n",
    "df[target_col] = pd.to_numeric(df[target_col], errors='coerce')\n",
    "# Condición para ejecutar código según un criterio\n",
    "if df[target_col].isna().any():\n",
    "    raise ValueError(\"La columna target no pudo convertirse completamente a numérico. Revisa valores atípicos.\")\n",
    "\n",
    "print('Distribución de clases (counts):')\n",
    "print(df[target_col].value_counts())\n",
    "print('\\nProporción (normalize):')\n",
    "# Asignación de variable o resultado intermedio\n",
    "print(df[target_col].value_counts(normalize=True))\n",
    "\n",
    "# Correlación numérica con Churn\n",
    "# Asignación de variable o resultado intermedio\n",
    "num_cols = df.select_dtypes(include=[np.number]).columns.tolist()\n",
    "# Condición para ejecutar código según un criterio\n",
    "if target_col in num_cols:\n",
    "    num_cols.remove(target_col)\n",
    "# Asignación de variable o resultado intermedio\n",
    "corr_with_y = df[num_cols + [target_col]].corr()[target_col].drop(target_col).sort_values(key=lambda x: x.abs(), ascending=False)\n",
    "print('\\nTop correlaciones (numéricas) con Churn:')\n",
    "display(corr_with_y.head(15))\n",
    "# --- Fin de celda ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e171be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inicio de celda: explicación de la lógica de esta sección ---\n",
    "# 4) Train/test split\n",
    "# Asignación de variable o resultado intermedio\n",
    "X = df.drop(columns=[target_col])\n",
    "# Asignación de variable o resultado intermedio\n",
    "y = df[target_col].astype(int)\n",
    "\n",
    "# Asignación de variable o resultado intermedio\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=RANDOM_STATE, stratify=y)\n",
    "print('Train shape:', X_train.shape, 'Test shape:', X_test.shape)\n",
    "\n",
    "# Detectar columnas categóricas (object / string), y numéricas\n",
    "# Asignación de variable o resultado intermedio\n",
    "cat_cols = selector(dtype_include=object)(X_train)\n",
    "# Asignación de variable o resultado intermedio\n",
    "num_cols = selector(dtype_include=np.number)(X_train)\n",
    "\n",
    "# Forzar categóricas a string (evitar mezcla de tipos)\n",
    "# Condición para ejecutar código según un criterio\n",
    "if len(cat_cols)>0:\n",
    "# Asignación de variable o resultado intermedio\n",
    "    X_train[cat_cols] = X_train[cat_cols].fillna('missing').astype(str)\n",
    "# Asignación de variable o resultado intermedio\n",
    "    X_test[cat_cols]  = X_test[cat_cols].fillna('missing').astype(str)\n",
    "\n",
    "print('\\nNuméricas:', len(num_cols), ' Categóricas:', len(cat_cols))\n",
    "# --- Fin de celda ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "056503a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inicio de celda: explicación de la lógica de esta sección ---\n",
    "# 5) Preprocesamiento y pipelines\n",
    "# Asignación de variable o resultado intermedio\n",
    "ohe = make_ohe()\n",
    "\n",
    "# Asignación de variable o resultado intermedio\n",
    "preprocess_scaled = ColumnTransformer(transformers=[\n",
    "    ('num', StandardScaler(), num_cols),\n",
    "    ('cat', ohe, cat_cols)\n",
    "# Asignación de variable o resultado intermedio\n",
    "], remainder='drop')\n",
    "\n",
    "# Asignación de variable o resultado intermedio\n",
    "preprocess_unscaled = ColumnTransformer(transformers=[\n",
    "    ('num', 'passthrough', num_cols),\n",
    "    ('cat', ohe, cat_cols)\n",
    "# Asignación de variable o resultado intermedio\n",
    "], remainder='drop')\n",
    "\n",
    "# Asignación de variable o resultado intermedio\n",
    "models = {\n",
    "# Asignación de variable o resultado intermedio\n",
    "    'LogisticRegression': Pipeline(steps=[\n",
    "        ('prep', preprocess_scaled),\n",
    "# Asignación de variable o resultado intermedio\n",
    "        ('clf', LogisticRegression(max_iter=2000, random_state=RANDOM_STATE))\n",
    "    ]),\n",
    "# Asignación de variable o resultado intermedio\n",
    "    'RandomForest': Pipeline(steps=[\n",
    "        ('prep', preprocess_unscaled),\n",
    "# Asignación de variable o resultado intermedio\n",
    "        ('clf', RandomForestClassifier(n_estimators=300, random_state=RANDOM_STATE))\n",
    "    ])\n",
    "}\n",
    "\n",
    "models.keys()\n",
    "# --- Fin de celda ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1292b08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inicio de celda: explicación de la lógica de esta sección ---\n",
    "# 6) Entrenar y evaluar\n",
    "# Definición de una función\n",
    "def eval_and_plot(name, model, X_te, y_te):\n",
    "# Asignación de variable o resultado intermedio\n",
    "    preds = model.predict(X_te)\n",
    "# Asignación de variable o resultado intermedio\n",
    "    probs = None\n",
    "    try:\n",
    "# Asignación de variable o resultado intermedio\n",
    "        probs = model.predict_proba(X_te)[:,1]\n",
    "    except Exception:\n",
    "        pass\n",
    "\n",
    "# Asignación de variable o resultado intermedio\n",
    "    acc  = accuracy_score(y_te, preds)\n",
    "# Asignación de variable o resultado intermedio\n",
    "    prec = precision_score(y_te, preds, zero_division=0)\n",
    "# Asignación de variable o resultado intermedio\n",
    "    rec  = recall_score(y_te, preds, zero_division=0)\n",
    "# Asignación de variable o resultado intermedio\n",
    "    f1   = f1_score(y_te, preds, zero_division=0)\n",
    "# Asignación de variable o resultado intermedio\n",
    "    auc  = roc_auc_score(y_te, probs) if probs is not None else np.nan\n",
    "\n",
    "    print(f\"== {name} ==\")\n",
    "# Asignación de variable o resultado intermedio\n",
    "    print(f\"Accuracy={acc:.4f}  Precision={prec:.4f}  Recall={rec:.4f}  F1={f1:.4f}  AUC={auc if not np.isnan(auc) else 'N/A'}\\n\")\n",
    "# Asignación de variable o resultado intermedio\n",
    "    print(classification_report(y_te, preds, digits=4))\n",
    "\n",
    "# Asignación de variable o resultado intermedio\n",
    "    cm = confusion_matrix(y_te, preds)\n",
    "# Asignación de variable o resultado intermedio\n",
    "    plt.figure(figsize=(4,3))\n",
    "# Asignación de variable o resultado intermedio\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "    plt.title(f\"Matriz de confusión — {name}\")\n",
    "    plt.xlabel('Predicho')\n",
    "    plt.ylabel('Real')\n",
    "    plt.show()\n",
    "\n",
    "# Condición para ejecutar código según un criterio\n",
    "    if probs is not None:\n",
    "# Asignación de variable o resultado intermedio\n",
    "        fpr, tpr, _ = roc_curve(y_te, probs)\n",
    "# Asignación de variable o resultado intermedio\n",
    "        plt.figure(figsize=(5,4))\n",
    "        plt.plot(fpr, tpr)\n",
    "# Asignación de variable o resultado intermedio\n",
    "        plt.plot([0,1],[0,1],'--', alpha=0.5)\n",
    "        plt.xlabel('FPR')\n",
    "        plt.ylabel('TPR')\n",
    "        plt.title(f'ROC curve — {name}')\n",
    "        plt.show()\n",
    "\n",
    "# Bucle para iterar sobre datos\n",
    "for name, model in models.items():\n",
    "    print('Entrenando', name)\n",
    "    model.fit(X_train, y_train)\n",
    "    eval_and_plot(name, model, X_test, y_test)\n",
    "\n",
    "# --- Fin de celda ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd4f0f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Inicio de celda: explicación de la lógica de esta sección ---\n",
    "# 7) Importancia de variables (RandomForest) y coeficientes (Logistic Regression)\n",
    "# Obtener nombres de features tras ColumnTransformer de forma robusta\n",
    "# Definición de una función\n",
    "def get_feature_names_from_columntransformer(ct, num_cols, cat_cols):\n",
    "    # num_cols are passed through first\n",
    "# Asignación de variable o resultado intermedio\n",
    "    feature_names = []\n",
    "    # numeric names\n",
    "    feature_names.extend(list(num_cols))\n",
    "    # categorical names from OHE\n",
    "    try:\n",
    "# Asignación de variable o resultado intermedio\n",
    "        ohe_step = ct.named_transformers_['cat']\n",
    "        # get_feature_names_out may require passing input features depending on sklearn version\n",
    "        try:\n",
    "# Asignación de variable o resultado intermedio\n",
    "            cat_names = list(ohe_step.get_feature_names_out(cat_cols))\n",
    "        except TypeError:\n",
    "# Asignación de variable o resultado intermedio\n",
    "            cat_names = list(ohe_step.get_feature_names_out())\n",
    "        feature_names.extend(cat_names)\n",
    "    except Exception as e:\n",
    "        # fallback: create simple placeholders\n",
    "# Bucle para iterar sobre datos\n",
    "        feature_names.extend([f'cat_{i}' for i in range(len(cat_cols))])\n",
    "    return feature_names\n",
    "\n",
    "# RandomForest\n",
    "# Asignación de variable o resultado intermedio\n",
    "rf = models['RandomForest']\n",
    "# Asignación de variable o resultado intermedio\n",
    "prep_rf = rf.named_steps['prep']\n",
    "# Asignación de variable o resultado intermedio\n",
    "rf_clf = rf.named_steps['clf']\n",
    "# Asignación de variable o resultado intermedio\n",
    "feature_names_rf = get_feature_names_from_columntransformer(prep_rf, num_cols, cat_cols)\n",
    "# Importación de librerías necesarias\n",
    "importances = rf_clf.feature_importances_\n",
    "# Importación de librerías necesarias\n",
    "imp_df = pd.DataFrame({'feature': feature_names_rf, 'importance': importances}).sort_values('importance', ascending=False)\n",
    "print('Top 20 features (RandomForest):')\n",
    "display(imp_df.head(20))\n",
    "\n",
    "# Logistic Regression\n",
    "# Asignación de variable o resultado intermedio\n",
    "lr = models['LogisticRegression']\n",
    "# Asignación de variable o resultado intermedio\n",
    "prep_lr = lr.named_steps['prep']\n",
    "# Asignación de variable o resultado intermedio\n",
    "lr_clf = lr.named_steps['clf']\n",
    "# Asignación de variable o resultado intermedio\n",
    "feature_names_lr = get_feature_names_from_columntransformer(prep_lr, num_cols, cat_cols)\n",
    "# Asignación de variable o resultado intermedio\n",
    "coefs = lr_clf.coef_.ravel()\n",
    "# Asignación de variable o resultado intermedio\n",
    "coef_df = pd.DataFrame({'feature': feature_names_lr, 'coef': coefs}).assign(abs_coef=lambda d: d['coef'].abs()).sort_values('abs_coef', ascending=False)\n",
    "print('Top 20 coefficients (LogisticRegression):')\n",
    "display(coef_df.head(20))\n",
    "# --- Fin de celda ---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97940c3b",
   "metadata": {},
   "source": [
    "## Conclusiones y siguientes pasos\n",
    "- Revisa las variables con mayor importancia y prueba modelos focalizados o técnicas de reducción/selección.\n",
    "- Considera balancear clases (SMOTE o undersampling) y re-evaluar recall/AUC si la clase positiva es minoritaria.\n",
    "- Implementar despliegue y monitoreo: recalibrar periodicámente, usar alertas para clientes con alta probabilidad de churn.\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
